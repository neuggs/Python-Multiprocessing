{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python's Multiprocessing Library\n",
    "\n",
    "Frank Neugebauer\n",
    "May 19, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parallel Corpus Preprocessor\n",
    "\n",
    "In a previous lesson, you created a corpus preprocessor to process the featured articles from Wikipedia. In this exercise, you will re-implement the preprocessor to use Pythonâ€™s multiprocessing library.machined died.\n",
    "### a. Read and JSONL Files\n",
    "\n",
    "The featured article data is spread across multiple files on the disk. Implement a function or class method that takes the JSONL file path as input, loads each JSON value, and returns a list of Python dictionaries as a result. \n",
    "\n",
    "For this code, I commented out the multiprocessing part due to security restrictions on my laptop. The code is otherwise complete. I am submitting a log file along with the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Processes\tTime to Process\n",
      "1\t\t\t1.8371\n",
      "2\t\t\t1.6708\n",
      "4\t\t\t1.669\n",
      "8\t\t\t1.6643\n",
      "16\t\t\t1.6483\n"
     ]
    }
   ],
   "source": [
    "def start_logger():\n",
    "    logging.basicConfig(filename ='./log/exercise_1_a_log_%s.log' %\n",
    "                        datetime.strftime(datetime.now(), '%m%d%Y_%H%M%S'),\n",
    "                        level = logging.DEBUG, format='%(asctime)s %(message)s', datefmt='%m-%d%H:%M:%S')\n",
    "\n",
    "def read_json_directory_time(n_processes):\n",
    "    logging.debug('In read_json_directory_time')\n",
    "    TEST_CODE = 'articles = read_json_directory(' + str(n_processes) + ')'\n",
    "    SETUP_CODE = '''from __main__ import read_json_directory'''\n",
    "    time = timeit.timeit(TEST_CODE, setup=SETUP_CODE, number = 1)\n",
    "    return time\n",
    "\n",
    "def read_article_jsonl(file_paths):\n",
    "    articles = []\n",
    "    logging.debug('In read_article_json...')\n",
    "    for file_path in file_paths:\n",
    "        logging.debug('Reading the ' + file_path + ' file...')\n",
    "        wiki_file_full = pd.read_json(file_path, lines=True)\n",
    "        articles.append(wiki_file_full.to_dict())\n",
    "    return articles\n",
    "\n",
    "def read_json_directory(n_processes):\n",
    "    WIKI_DIR = '../../data/wikipedia//featured-articles'\n",
    "    logging.debug('In read_json_directory...')\n",
    "    logging.debug('Building paths...')\n",
    "    json_file_paths = [\n",
    "        entry.path\n",
    "        for entry in os.scandir(WIKI_DIR) if entry.name.endswith('.jsonl')\n",
    "    ]\n",
    "    logging.debug('Starting the pooling...')\n",
    "    articles = read_article_jsonl(json_file_paths)\n",
    "    logging.debug('There are ' + str(len(articles)) + ' dictionaries in the articles list.')\n",
    "    logging.debug('Finished building the article dictionary.')\n",
    "    \"\"\"\n",
    "    with Pool(processes=n_processes) as pool:\n",
    "        articles = pool.map(read_article_jsonl, json_file_paths) \n",
    "    \"\"\"\n",
    "    return articles\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_logger()\n",
    "    logging.debug('Starting read_json_directory...')\n",
    "\n",
    "    times = []\n",
    "    n_proc = [1, 2, 4, 8, 16]\n",
    "    for this_proc in n_proc:\n",
    "        this_record = {}\n",
    "        time = read_json_directory_time(this_proc)\n",
    "        this_record['# Processes'] = this_proc\n",
    "        this_record['Time to Process'] = round(time, 4)\n",
    "        times.append(this_record)\n",
    "\n",
    "    print(\"# Processes\\tTime to Process\")\n",
    "    for i in times:\n",
    "        print(\"{}\\t\\t\\t{}\".format(i['# Processes'],i['Time to Process']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
