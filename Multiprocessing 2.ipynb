{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This workflow is designed to take any type of text document and vectorize it. As a pipeline, it actually\n",
    "can take a directory of files (corpora), ingest them, clean them, and tokenize them.\n",
    "\n",
    "The tasks diverge and then converge.\n",
    "\"\"\"\n",
    "\n",
    "def read_raw_data(file_location):\n",
    "    \"\"\"\n",
    "    This function reads the raw data in whatever form it's in (e.g., CSV, JSONL). \n",
    "    Args:\n",
    "        file_location - where the file(s) are on a disk or remote location.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame - the data in an easy-to-use format for processing.\n",
    "    \"\"\"\n",
    "\n",
    "def clean_data(raw_data):\n",
    "    \"\"\"\n",
    "    Once the data is read, cleaning is required (most of the time). This step and the following step\n",
    "    are piped together.\n",
    "    Args:\n",
    "        raw_data - the data from the last step.\n",
    "    Returns:\n",
    "        clean_data - data in a form (e.g., no stopwords, \\n, \\t, or missing data).\n",
    "    \"\"\"\n",
    "\n",
    "def process_data(clean_data):\n",
    "    \"\"\"\n",
    "    This is a variable step and may include building train and test instances along with vectorizing dadta. \n",
    "    This step and clean_data can be thought of together and the output sent to the classifier (or other algo).\n",
    "    Args:\n",
    "        raw_data_df - the data from the read_raw_data step.\n",
    "    Returns:\n",
    "        vector_data - the data as a vector (in this kind of problem).\n",
    "    \"\"\"\n",
    "\n",
    "def run_model(classifier, vector_data[features], vector_data[target], optional_args):\n",
    "    \"\"\"\n",
    "    This is where the real work gets done and depends entirely on the problem being solved. For example, in Ex 2.2,\n",
    "    various (e.g., Naive Bayes, LogisticRegression) classifiers were used.\n",
    "    Args:\n",
    "        classfier - an object of type matching the work being done.\n",
    "        vector_data[features] - the vectors for the features being used.\n",
    "        vector_data[target] - the target. \n",
    "        optional_args - a dictionary with algorithm-specific hyperparameters.\n",
    "    \"\"\"\n",
    "def \n",
    "workflow = {\n",
    "    'tasks': [\n",
    "        (read_raw_data, clean_data),\n",
    "        (read_raw_data, process_data),\n",
    "        (clean_data, run_model),\n",
    "        (process_data, run_model)\n",
    "    ],\n",
    "    'params': {\n",
    "        'file_location': 'SOMELOCATION'\n",
    "        'raw_data': 'DATAFRAME'\n",
    "        'clean_data': 'DATAFRAME OR TEXT'\n",
    "        'classifier': 'DEPENDS ON ALGO'\n",
    "        'vector_data[features]', 'VECTOR'\n",
    "        'vector_data[target]', 'TARGET'\n",
    "        'optional_args', 'DICTIONARY'\n",
    "    }\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
